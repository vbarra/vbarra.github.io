{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Machine Learning\n",
        "image: ../img/emvplot.png\n",
        "page-layout: full\n",
        "about:\n",
        "  template: solana\n",
        "  image-width: 12em\n",
        "  image-shape: round\n",
        "---"
      ],
      "id": "479a290b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Course description**"
      ],
      "id": "9fca5feb"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Introduction to supervised and unsupervised machine learning algorithms. Applications in Python using <a href=\"https://scikit-learn.org/stable/\" target=\"_blank\">scikit-learn </a>\n",
        "\n",
        "#### **Syllabus**\n",
        "---"
      ],
      "id": "ae2996e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Introduction to Machine Learning and to developement tools\n",
        "2. Feature selection and Manifold learning\n",
        "3. Classification algorithms\n",
        "4. Kernel methods for classification and regression\n",
        "5. Ensemble methods\n",
        "6. Hidden Markov Models\n",
        "\n",
        "\n",
        "#### **Example**"
      ],
      "id": "56237dd4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "Illustration on supervised classification methodss"
      ],
      "id": "26355948"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "plt.title(\"Binary classificatin dataset\", fontsize=\"small\")\n",
        "X, Y = make_classification(n_samples=500, n_features=2, n_redundant=0, n_informative=2)\n",
        "plt.scatter(X[:, 0], X[:, 1], marker=\"o\", c=Y, s=25, edgecolor=\"k\",cmap=plt.cm.rainbow)\n",
        "plt.tight_layout()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.25,shuffle=True)\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "\n",
        "def affiche(X,y,met,title):\n",
        "    met.fit(X_train,y_train)\n",
        "    y_predict = met.predict(X_test)\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    axs[0].scatter(X[:, 0], X[:, 1], marker=\"o\", c=Y, s=25, cmap=plt.cm.rainbow,edgecolor=\"k\")\n",
        "    axs[0].set_title('Données',fontsize=10)\n",
        "    axs[1].scatter(X_train[:, 0], X_train[:, 1],c = y_train, s=30,marker='*', cmap=plt.cm.rainbow,edgecolor=\"k\",alpha=0.25,label='train')\n",
        "    axs[1].scatter(X_test[:, 0], X_test[:, 1],c = y_predict, s=30, cmap=plt.cm.rainbow,edgecolor=\"k\")\n",
        "    axs[1].set_title('Test classification : '+title,fontsize=10)\n",
        "    axs[1].legend(loc='best')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def decision(modele, X, y, title,ax,axes=[-1.5, 2.5, -1, 1.5], alpha=0.5):\n",
        "    x1s = np.linspace(axes[0], axes[1], 200)\n",
        "    x2s = np.linspace(axes[2], axes[3], 200)\n",
        "    x1, x2 = np.meshgrid(x1s, x2s)\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred = modele.predict(X_new).reshape(x1.shape)\n",
        "    map = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "    ax.contourf(x1, x2, y_pred, alpha=0.7, cmap=map)\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.rainbow,edgecolors='k')\n",
        "    ax.set_title(title)\n",
        "\n",
        "\n",
        "##### Classifiers without hyperparameter optimization\n",
        "classifieurs = {'Bayes':[GaussianNB(),0,0],\n",
        "                'LDA':[LinearDiscriminantAnalysis(solver='eigen'),0,1],\n",
        "                'QDA':[QuadraticDiscriminantAnalysis(),1,0],\n",
        "                'knn':[KNeighborsClassifier(),1,1], \n",
        "                'arbre':[DecisionTreeClassifier(),2,0],\n",
        "                'svmlin':[LinearSVC(dual=True),2,1],\n",
        "                'svmrbf':[SVC(kernel='rbf'),3,0],\n",
        "                'svmpoly':[SVC(kernel='poly'),3,1]    \n",
        "               } \n",
        "fig, axs = plt.subplots(4, 2,figsize=(10,14))\n",
        "for name,met in classifieurs.items():\n",
        "    classifieurs[name][0].fit(X_train,y_train)\n",
        "    classifieurs[name][0].fit(X_train,y_train)\n",
        "    ypredict = classifieurs[name][0].predict(X_test)\n",
        "    pos = axs[classifieurs[name][1],classifieurs[name][2]]\n",
        "\n",
        "    pos.scatter(X_train[:, 0], X_train[:, 1],c = y_train, s=30,marker='*', cmap=plt.cm.rainbow,edgecolor=\"k\",alpha=0.25,label='train')\n",
        "    pos.scatter(X_test[:, 0], X_test[:, 1],c = ypredict, s=30, cmap=plt.cm.rainbow,edgecolor=\"k\")\n",
        "    pos.set_title('Classification des données de test : '+name,fontsize=10)\n",
        "    pos.legend(loc='best')\n",
        " \n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "##### Hyperparameter optimization using CV and GridSearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param = {\n",
        "        'Bayes':[{'var_smoothing':[1e-9,1e-5,0.1]}],\n",
        "        'LDA':[{'shrinkage':[0,0.5,1]}],\n",
        "        'QDA':[{'tol':[1e-4,1e-2,1e-1]}],\n",
        "        'knn':[{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 5, 7]}], \n",
        "         'arbre':[{'criterion': ['entropy', 'gini'], 'max_depth':np.arange(1, 10),'min_samples_leaf': np.arange(1, 10)}],\n",
        "        'svmlin':{'C':np.arange(0.01,100,10)},\n",
        "         'svmrbf':{\"C\": [1e-1, 1e1, 1e2,1e4],\"gamma\": [0.01,  0.1,0.5, 1,10]},\n",
        "         'svmpoly':{\"degree\": np.arange(1,10),\"coef0\": np.arange(-5,5)}\n",
        "        }\n",
        "predict = {'Bayes':[],\n",
        "            'LDA':[],\n",
        "            'QDA':[],\n",
        "           'knn':[], \n",
        "            'arbre':[],\n",
        "            'svmlin':[],\n",
        "            'svmrbf':[],\n",
        "            'svmpoly':[],        \n",
        "               } \n",
        "\n",
        "bestalgo = {'Bayes':[],\n",
        "            'LDA':[],\n",
        "            'QDA':[],\n",
        "           'knn':[], \n",
        "            'arbre':[],\n",
        "            'svmlin':[],\n",
        "            'svmrbf':[],\n",
        "            'svmpoly':[],        \n",
        "               } \n",
        "\n",
        "for name,met in classifieurs.items():\n",
        "    gs = GridSearchCV(met[0], param[name], cv=5, verbose=1, n_jobs=-1)\n",
        "    gs.fit(X_train, y_train)\n",
        "    print(\"est parameters for \"+ name ,gs.best_params_)\n",
        "    \n",
        "    bestalgo[name] = gs.best_estimator_\n",
        "    bestalgo[name].fit(X_train,y_train)\n",
        "    predict[name] = bestalgo[name].predict(X_test)\n",
        "\n",
        "##### Measures of performance\n",
        "from sklearn.metrics import classification_report\n",
        "for key,values in predict.items():\n",
        "    print(\"*** Results for \", key,' ***')\n",
        "    print(classification_report(y_test, values))\n",
        "\n",
        "\n",
        "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
        "\n",
        "fig,ax = plt.subplots()\n",
        "for key,values in predict.items():\n",
        "    RocCurveDisplay.from_estimator(classifieurs[key][0], X_test, y_test, ax=ax, name=key)\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(4, 2,figsize=(10,14))\n",
        "for name,met in classifieurs.items():\n",
        "    bestalgo[name].fit(X_train,y_train)\n",
        "    bestalgo[name].fit(X_train,y_train)\n",
        "    predict[name] = bestalgo[name].predict(X_test)\n",
        "    pos = axs[classifieurs[name][1],classifieurs[name][2]]\n",
        "    decision(bestalgo[name], X_train, y_train,title=name, ax=pos,axes=[np.min(X[:,0]), np.max(X[:,0]), np.min(X[:,1]), np.max(X[:,1])])\n",
        "plt.tight_layout()"
      ],
      "id": "6605f1e0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "deepenv",
      "language": "python",
      "display_name": "deepenv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}